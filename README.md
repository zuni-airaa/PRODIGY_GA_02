```markdown
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1u6qigQb-k0Q4CRnphkJjVcrCfaBjCI4e#scrollTo=YOmwqjSJiO03)

# PRODIGY_GA_02

##  Project Overview
This project demonstrates textâ€‘toâ€‘image generation using **Stable Diffusion** and **DALLâ€‘Eâ€‘mini**, two stateâ€‘ofâ€‘theâ€‘art generative models. By providing descriptive prompts, the models generate unique and creative visuals, showcasing the potential of diffusion models in AIâ€‘driven art and design.

##  Features
- Image generation from natural language prompts  
- Comparison between Stable Diffusion and DALLâ€‘Eâ€‘mini outputs  
- Curated `prompts.txt` dataset for testing  
- Example outputs showcasing generated images  

##  Repository Structure
- `notebooks/` â†’ Colab notebook for image generation  
- `data/` â†’ Curated prompt dataset (`prompts.txt`)  
- `results/` â†’ Generated image samples  
- `README.md` â†’ Project documentation  
- `requirements.txt` â†’ Dependencies  

##  Setup
Install dependencies:
```bash
pip install diffusers transformers torch accelerate
```

Run the notebook in Google Colab or locally to generate images from prompts.

##  References
- HuggingFace Diffusers: [Stable Diffusion documentation](https://huggingface.co/docs/diffusers/index)  
- Colab Notebook: [Textâ€‘toâ€‘Image tutorial](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb)  

##  Example Usage
```python
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("cuda")

prompt = "A futuristic cityscape at sunset, highly detailed, digital art"
image = pipe(prompt).images[0]

image.save("results/sample_output.png")
```

##  Results

Here are some example outputs generated using Stable Diffusion:

**Prompt:**  
`A futuristic cityscape at sunset, highly detailed, digital art`

**Generated Output:**  
*(Image stored in `results/sample_output.png`)*

---

**Prompt:**  
`A watercolor painting of mountains and lakes`

**Generated Output:**  
*(Image stored in `results/sample_output2.png`)*

---

Sample outputs are stored in the `results/` folder for reference.
```
## ðŸ“‚ Repository Structure

PRODIGY_GA_02/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ PRODIGY_GA_02.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ prompts.txt
â”œâ”€â”€ results/
â”‚   â””â”€â”€ samples/
â”‚       â”œâ”€â”€ output_1.png
â”‚       â”œâ”€â”€ output_2.png
â”‚       â”œâ”€â”€ output_3.png
â”‚       â”œâ”€â”€ output_4.png
â”‚       â””â”€â”€ output_5.png
â”œâ”€â”€ requirements/
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ README.md


This mirrors Taskâ€‘01 exactly â€” same badge, headings, flow, and example usage â€” but adapted for image generation.  

Would you like me to also prepare a **matching LinkedIn post draft** for Taskâ€‘02, so your announcement looks consistent with Taskâ€‘01â€™s style?
